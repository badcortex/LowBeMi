{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn-extra\n",
        "!pip install larq larq-compute-engine"
      ],
      "metadata": {
        "id": "9T2vfhHkvicn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H-pxbj29uY-l"
      },
      "outputs": [],
      "source": [
        "import larq_compute_engine as lce\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import larq as lq\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import shuffle\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"/content/drive/My Drive/LowBeMi\""
      ],
      "metadata": {
        "id": "uP07nj-FPqbo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clusterSampling(x_train, y_train, imgs_per_class):\n",
        "  \"\"\" Creazione dizionario contenente k immagini per classe campionate utilizzando kMedoids. \"\"\"\n",
        "  train_data = dict.fromkeys(np.unique(y_train))\n",
        "\n",
        "  for k in train_data.keys():\n",
        "    k_filter = np.where(y_train == k)[0]\n",
        "    k_images = x_train[k_filter[0:]]\n",
        "    kmedoids = KMedoids(n_clusters=imgs_per_class).fit(k_images.reshape(len(k_images), -1))\n",
        "    train_data[k] = kmedoids.cluster_centers_.reshape(imgs_per_class, 28, 28)\n",
        "\n",
        "  return train_data"
      ],
      "metadata": {
        "id": "bpQD9qF_8VPW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printImages(train_data):\n",
        "  \"\"\" Funzione per la visiaulizzazione di ogni prima immagini per ogni classe. \"\"\"\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  fig, axes = plt.subplots(1, len(train_data))\n",
        "\n",
        "  for idx, (key, images) in enumerate(train_data.items()):\n",
        "      axes[idx].imshow(images[0], cmap='gray')\n",
        "      axes[idx].set_title(f'Class {key}')\n",
        "      axes[idx].axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "F17pBnsHF4Se"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessImages(input_data, target_size=(8, 8)):\n",
        "    \"\"\" Funzione per normalizzazione e ridimensionamento delle immagini campionate. \"\"\"\n",
        "    preprocessed_data = {}\n",
        "\n",
        "    for label, images in input_data.items():\n",
        "        num_images, height, width = images.shape\n",
        "\n",
        "        flat_images = images.reshape(num_images, -1)\n",
        "        scaler = MinMaxScaler()\n",
        "        normalized_images = scaler.fit_transform(flat_images)\n",
        "\n",
        "        resized_images = []\n",
        "        for i in range(num_images):\n",
        "            image = normalized_images[i].reshape(height, width)\n",
        "            resized_image = resize(image, output_shape=target_size, mode='constant', anti_aliasing=True)\n",
        "            resized_images.append(resized_image)\n",
        "\n",
        "        preprocessed_data[label] = np.array(resized_images)\n",
        "\n",
        "    return preprocessed_data"
      ],
      "metadata": {
        "id": "3ZJxQpq487jG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getShuffledTrainingData(train_data_dict, i, j, imgs_per_class):\n",
        "  \"\"\" Funzione per la creazione del dataset (i,j) per il training di ogni rete. \"\"\"\n",
        "  train_data = np.concatenate((train_data_dict[i], train_data_dict[j]))\n",
        "  train_labels = np.concatenate(([i] * imgs_per_class, [j] * imgs_per_class))\n",
        "\n",
        "  train_data, train_labels = shuffle(train_data, train_labels)\n",
        "\n",
        "  return train_data, train_labels"
      ],
      "metadata": {
        "id": "904y8cU0rSW6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BNN(architecture, lr):\n",
        "  \"\"\" Funzione per la creazione di una BNN. \"\"\"\n",
        "  input_layer, h1_layer, h2_layer, output_layer = architecture\n",
        "\n",
        "  model = tf.keras.models.Sequential(\n",
        "      [\n",
        "          tf.keras.layers.Flatten(),\n",
        "          lq.layers.QuantDense(input_layer, kernel_quantizer=\"ste_sign\", kernel_constraint=\"weight_clip\"),\n",
        "          lq.layers.QuantDense(h1_layer, input_quantizer=\"ste_sign\",\n",
        "                              kernel_quantizer=lq.quantizers.SteTern(threshold_value=0.05, ternary_weight_networks=True, clip_value=1.0),\n",
        "                              activation=\"hard_tanh\"),\n",
        "          lq.layers.QuantDense(h2_layer, input_quantizer=\"ste_sign\",\n",
        "                              kernel_quantizer=lq.quantizers.SteTern(threshold_value=0.05, ternary_weight_networks=True, clip_value=1.0),\n",
        "                              activation=\"hard_tanh\"),\n",
        "          lq.layers.QuantDense(output_layer, input_quantizer=\"ste_sign\",\n",
        "                              kernel_quantizer=lq.quantizers.SteTern(threshold_value=0.05, ternary_weight_networks=True, clip_value=1.0),\n",
        "                              activation=\"hard_tanh\")\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "  model.compile(optimizer=opt,\n",
        "                loss='squared_hinge',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "yJAtA0WckJ5r"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainModels(train_data_dict, imgs_per_class):\n",
        "  \"\"\" Funzione per l'addestramento delle singole BNN. \"\"\"\n",
        "  classes = train_data_dict.keys()\n",
        "\n",
        "  for i in range(len(classes)):\n",
        "    for j in range(i+1, len(classes)):\n",
        "\n",
        "      print(f\"BNN {i}{j}\")\n",
        "\n",
        "      # Crezione dataset (i,j) per addestrare la BNN(i,j)\n",
        "      train_data, train_labels_ij = getShuffledTrainingData(train_data_dict, i, j, imgs_per_class)\n",
        "\n",
        "      # Encoding della label\n",
        "      enc = LabelBinarizer()\n",
        "      enc.fit(np.unique(train_labels_ij))\n",
        "      encoded_labels = enc.transform(train_labels_ij)\n",
        "\n",
        "      earlystopping = tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
        "                                                      mode=\"auto\", patience=1,\n",
        "                                                      restore_best_weights=True)\n",
        "\n",
        "      # Creazione e addestramento della BNN(i,j)\n",
        "      model = BNN(architecture, lr)\n",
        "      model.fit(train_data, encoded_labels.flatten(), epochs=5, batch_size=1, callbacks=[earlystopping])\n",
        "\n",
        "      # Salvataggio del modello in formato .tflite\n",
        "      converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "      tflite_model = converter.convert()\n",
        "      with open(f\"/content/drive/My Drive/LowBeMi/model{i}{j}.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)"
      ],
      "metadata": {
        "id": "efWkmmgMKw22"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictSingleModel(i, j, test_data):\n",
        "  bnn_model = tf.lite.Interpreter(f\"/content/drive/My Drive/LowBeMi/model{i}{j}.tflite\")\n",
        "\n",
        "  # Allocazione della momeria per ogni modello\n",
        "  bnn_model.allocate_tensors()\n",
        "\n",
        "  # Indici per tensori di input e output\n",
        "  bnn_model_input_index = bnn_model.get_input_details()[0][\"index\"]\n",
        "  bnn_model_output_index = bnn_model.get_output_details()[0][\"index\"]\n",
        "\n",
        "  bnn_model_predictions = []\n",
        "\n",
        "  # Run each model's interpreter for each value and store the results in arrays\n",
        "  for x_value in x_test:\n",
        "    # Create a 2D tensor wrapping the current x value\n",
        "    x_value_tensor = tf.convert_to_tensor([x_value], dtype=np.float32)\n",
        "    # Write the value to the input tensor\n",
        "    bnn_model.set_tensor(bnn_model_input_index, x_value_tensor)\n",
        "    # Run inference\n",
        "    bnn_model.invoke()\n",
        "    # Read the prediction from the output tensor\n",
        "    bnn_model_predictions.append(bnn_model.get_tensor(bnn_model_output_index)[0])\n",
        "\n",
        "  threshold = 0.05\n",
        "  for p in bnn_model_predictions:\n",
        "    if p[0] > threshold:\n",
        "      p[0] = 1\n",
        "    elif p[0] < -threshold:\n",
        "      p[0] = -1\n",
        "    else:\n",
        "      p[0] = np.nan\n",
        "\n",
        "  enc = LabelBinarizer()\n",
        "  enc.fit((i, j))\n",
        "  predicted_labels = enc.inverse_transform(np.array(bnn_model_predictions))\n",
        "\n",
        "  return predicted_labels"
      ],
      "metadata": {
        "id": "oqSLLxBIMiNj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictEnsemble(classes, test_data):\n",
        "  n_models = 0\n",
        "\n",
        "  for i in range(len(classes)):\n",
        "    for j in range(i+1, len(classes)):\n",
        "      n_models += 1\n",
        "\n",
        "  single_preds_matrix = np.zeros((n_models, len(test_data)))\n",
        "\n",
        "  k = 0\n",
        "  for i in range(len(classes)):\n",
        "    for j in range(i+1, len(classes)):\n",
        "      single_preds_matrix[k, :] = predictSingleModel(i, j, test_data)\n",
        "      k += 1\n",
        "\n",
        "  ensemble_preds = []\n",
        "\n",
        "  for k in range(len(test_data)):\n",
        "    preds, counts = np.unique(single_preds_matrix[:, k], return_counts=True)\n",
        "    poll = dict(zip(preds, counts))\n",
        "    ensemble_preds.append(max(poll, key = lambda x: poll[x]))\n",
        "\n",
        "  return ensemble_preds"
      ],
      "metadata": {
        "id": "K_lZAxbzpPUN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Reshape immagini\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))"
      ],
      "metadata": {
        "id": "O8ye4RdOu72x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 80                        # Numero di immagini per classe\n",
        "lr = 0.01                     # Learning rate\n",
        "architecture = [64, 4, 4, 1]  # Architetture delle reti dell'ensemble\n",
        "\n",
        "# Campionamento delle k immagini per classe tramite kMedoids\n",
        "data = clusterSampling(train_images, train_labels, k)\n",
        "\n",
        "# Normalizzazione e ridimensionamento delle immagini\n",
        "data = preprocessImages(data)"
      ],
      "metadata": {
        "id": "nhU1lEnItojn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizzazione della prima immagine di ogni classe\n",
        "printImages(data)"
      ],
      "metadata": {
        "id": "Qm_mTfy3GGeC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "d198af90-8a22-4a18-fc7c-f0ef040b7e4b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dei modelli\n",
        "trainModels(data, k)"
      ],
      "metadata": {
        "id": "Cdz784SLcp-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversione dei modelli salvati per\n",
        "%%bash\n",
        "\n",
        "for ((i=0; i<10; i++)); do\n",
        "    for ((j=i+1; j<10; j++)); do\n",
        "        xxd -i \"/content/drive/My Drive/LowBeMi/model${i}${j}.tflite\" > \"/content/drive/My Drive/LowBeMi/bnn${i}${j}.cc\"\n",
        "    done\n",
        "done"
      ],
      "metadata": {
        "id": "B3rmPZA-noax"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = [data[0][9], data[1][0], data[2][0], data[3][1], data[4][1], data[5][2],\n",
        "          data[6][2], data[7][3], data[8][3], data[9][4]]"
      ],
      "metadata": {
        "id": "p3Axmn9Ylfey"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = predictEnsemble(data.keys(), x_test)"
      ],
      "metadata": {
        "id": "4Tyj_w23zX5j"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}